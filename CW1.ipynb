{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesbrowne98/jamesbrowne98/blob/main/CW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-8auguNkXfEN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JAw8EZLffJ1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(\"ENB2012_data.xlsx\")\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au_fEgPDoXG-",
        "outputId": "08a4a41a-c2db-4c8b-f9e6-0a304ad11a3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
            "0    0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
            "1    0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
            "2    0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
            "3    0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
            "4    0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28\n",
            "..    ...    ...    ...     ...  ...  ..  ...  ..    ...    ...\n",
            "763  0.64  784.0  343.0  220.50  3.5   5  0.4   5  17.88  21.40\n",
            "764  0.62  808.5  367.5  220.50  3.5   2  0.4   5  16.54  16.88\n",
            "765  0.62  808.5  367.5  220.50  3.5   3  0.4   5  16.44  17.11\n",
            "766  0.62  808.5  367.5  220.50  3.5   4  0.4   5  16.48  16.61\n",
            "767  0.62  808.5  367.5  220.50  3.5   5  0.4   5  16.64  16.03\n",
            "\n",
            "[768 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "inputs = data.values[:,:8].astype(float)\n",
        "targets = data.values[:,8:].astype(float)\n",
        "print(np.shape(inputs))\n",
        "\n",
        "#Normalize the inputs\n",
        "scaler = MinMaxScaler()\n",
        "scaled_inputs = scaler.fit_transform(inputs)\n",
        "scaled_targets = scaler.fit_transform(targets)\n",
        "\n",
        "print(scaled_inputs)\n",
        "print(scaled_targets)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O68LcnljEu8f",
        "outputId": "dd1013d4-7711-4e54-f79e-91735b4ef5e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8)\n",
            "[[1.         0.         0.28571429 ... 0.         0.         0.        ]\n",
            " [1.         0.         0.28571429 ... 0.33333333 0.         0.        ]\n",
            " [1.         0.         0.28571429 ... 0.66666667 0.         0.        ]\n",
            " ...\n",
            " [0.         1.         0.71428571 ... 0.33333333 1.         1.        ]\n",
            " [0.         1.         0.71428571 ... 0.66666667 1.         1.        ]\n",
            " [0.         1.         0.71428571 ... 1.         1.         1.        ]]\n",
            "[[0.25721219 0.28090493]\n",
            " [0.25721219 0.28090493]\n",
            " [0.25721219 0.28090493]\n",
            " ...\n",
            " [0.28120787 0.1672502 ]\n",
            " [0.28228633 0.153784  ]\n",
            " [0.28660016 0.13816321]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor"
      ],
      "metadata": {
        "id": "CcyVIVIf8lEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor()\n",
        "regressor.fit(scaled_inputs, scaled_targets)\n",
        "outputs = regressor.predict(scaled_inputs)\n",
        "print(\"Random Forest Regressor: \\n\", outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOY0l5J2oqRh",
        "outputId": "c126a44b-a274-4c29-a42b-8ad27d65511d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor: \n",
            " [[0.2634268  0.28869109]\n",
            " [0.26277164 0.28343119]\n",
            " [0.25999461 0.28296795]\n",
            " ...\n",
            " [0.28319493 0.16380824]\n",
            " [0.28425991 0.15234043]\n",
            " [0.28623349 0.14269324]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network Regressor"
      ],
      "metadata": {
        "id": "pBfIoOEVC8pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "regressor_NN = MLPRegressor(max_iter=5000)\n",
        "regressor_NN.fit(scaled_inputs, scaled_targets)\n",
        "outputs = regressor_NN.predict(scaled_inputs)\n",
        "print(\"MLP Regressor: \\n\", outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIs9ktkC8ygs",
        "outputId": "8798fab5-7aa8-4fc7-be64-a1744864d9b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Regressor: \n",
            " [[0.45570695 0.42530066]\n",
            " [0.43004507 0.43143756]\n",
            " [0.40502961 0.43861081]\n",
            " ...\n",
            " [0.34529151 0.23262214]\n",
            " [0.34209378 0.24147208]\n",
            " [0.33445473 0.26312872]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine Regressor\n"
      ],
      "metadata": {
        "id": "GIRJY-P_ecCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first the Y's must be split and normalized\n",
        "from sklearn.svm import SVR\n",
        "targetY1 = data[\"Y1\"]\n",
        "targetY2 = data[\"Y2\"]\n",
        "x = data.iloc[:,0:8].values\n",
        "y = data.iloc[:,8:10].values"
      ],
      "metadata": {
        "id": "UMP2iEs7e2EO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "y = scaler.fit_transform(y)"
      ],
      "metadata": {
        "id": "UHJ8u0VSjssr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y1 = y[:,:1]\n",
        "Y2 = y[:,1:]"
      ],
      "metadata": {
        "id": "158nWd6wkF35"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y1_reg = SVR()\n",
        "Y1_reg.fit(x, Y1.reshape(-1))\n",
        "predY1 = Y1_reg.predict(x)\n",
        "print(predY1)"
      ],
      "metadata": {
        "id": "tAgCxwu4kWEb",
        "outputId": "cf3ba4e1-9be7-4124-f5c8-facabf7dc6b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35504785 0.35751805 0.34678964 0.33296785 0.36429904 0.36669783\n",
            " 0.35395753 0.33960422 0.32054237 0.32290067 0.30875848 0.29261367\n",
            " 0.40806651 0.42168256 0.41235271 0.39295674 0.51421049 0.54080088\n",
            " 0.53698344 0.51302093 0.57002719 0.58332993 0.58614496 0.58343891\n",
            " 0.10205707 0.06996078 0.06919454 0.10120301 0.09673619 0.0652879\n",
            " 0.06496452 0.09701465 0.10567137 0.07615456 0.07597874 0.10628157\n",
            " 0.12352517 0.09616953 0.09584518 0.12362224 0.145869   0.12045472\n",
            " 0.11968227 0.1446808  0.17011947 0.14612533 0.14474247 0.16721685\n",
            " 0.51860932 0.54542511 0.53249166 0.49283359 0.52076132 0.54068811\n",
            " 0.52673489 0.49509454 0.44674132 0.46332163 0.44874585 0.41950487\n",
            " 0.54991281 0.57570794 0.56642783 0.53670808 0.68085293 0.7196459\n",
            " 0.71580074 0.68135483 0.7475017  0.76837258 0.76828911 0.75566425\n",
            " 0.10515089 0.07470143 0.07579474 0.10907555 0.10382775 0.07516456\n",
            " 0.07774014 0.11146189 0.11858449 0.09336956 0.09705277 0.1289372\n",
            " 0.14154095 0.12000203 0.12439522 0.15351462 0.16751226 0.14906153\n",
            " 0.15355012 0.17955824 0.19258184 0.1760734  0.1801625  0.20344336\n",
            " 0.54149851 0.57193673 0.56489119 0.53052548 0.53479936 0.55308573\n",
            " 0.54541339 0.52481525 0.45436783 0.46887372 0.46178943 0.44570522\n",
            " 0.56390995 0.58498078 0.58129793 0.56451057 0.70624559 0.73925673\n",
            " 0.73883941 0.71514603 0.78262868 0.7983242  0.79837736 0.79130363\n",
            " 0.11128326 0.08050739 0.08273727 0.11797225 0.11127593 0.08205893\n",
            " 0.08551797 0.1210342  0.1276122  0.10186599 0.10623346 0.13959214\n",
            " 0.15174381 0.12989192 0.13481625 0.1649735  0.17823605 0.15978907\n",
            " 0.16476187 0.19143792 0.20286131 0.18667483 0.19127102 0.21495655\n",
            " 0.54849864 0.57649546 0.5754567  0.55215943 0.53745505 0.54829604\n",
            " 0.54632328 0.54105094 0.45705388 0.46343345 0.46264941 0.46336452\n",
            " 0.57045391 0.58081522 0.58098591 0.57980997 0.71903603 0.74035626\n",
            " 0.74133918 0.73054882 0.80173151 0.81010625 0.80962491 0.80858382\n",
            " 0.13255503 0.10154398 0.10405049 0.139786   0.13365864 0.10380689\n",
            " 0.10710295 0.14284954 0.15040056 0.1238232  0.12771567 0.16103437\n",
            " 0.17404886 0.15143124 0.15570635 0.18551509 0.19933081 0.18036057\n",
            " 0.18470044 0.2108351  0.22200354 0.2056553  0.20977586 0.23282509\n",
            " 0.54540441 0.5653482  0.56757961 0.55650488 0.5380344  0.53712805\n",
            " 0.53694795 0.54496997 0.46455037 0.45829358 0.4589843  0.47334697\n",
            " 0.57930806 0.57512836 0.5741888  0.58453715 0.72781501 0.73399421\n",
            " 0.73171376 0.72977978 0.80969593 0.81046219 0.80732866 0.80889658\n",
            " 0.16686792 0.13576137 0.13717947 0.17119245 0.16874626 0.13832962\n",
            " 0.14000166 0.17368022 0.18463103 0.15713574 0.1590653  0.1901612\n",
            " 0.20606869 0.18245549 0.18466412 0.21219261 0.22842702 0.20859777\n",
            " 0.21101056 0.23496466 0.24774298 0.23087792 0.23340114 0.25445587\n",
            " 0.53883672 0.54729551 0.54847141 0.54637635 0.54309157 0.52903721\n",
            " 0.5252122  0.53954666 0.48212201 0.46180842 0.45767371 0.47748409\n",
            " 0.59507851 0.575889   0.56786537 0.58105649 0.7365382  0.72748776\n",
            " 0.71671605 0.71567548 0.80903632 0.80359318 0.79524583 0.79387184\n",
            " 0.21052523 0.17983562 0.17884472 0.20864387 0.21280889 0.18238025\n",
            " 0.18112896 0.21024078 0.22676162 0.19882222 0.19754839 0.22408957\n",
            " 0.24459477 0.22032938 0.21935412 0.2425838  0.26272171 0.24223317\n",
            " 0.24172818 0.26181373 0.27769482 0.26040598 0.26047906 0.27816147\n",
            " 0.65759743 0.69532518 0.68000208 0.62730866 0.6488621  0.67422\n",
            " 0.65969535 0.62312291 0.54622108 0.5625375  0.54637554 0.5162105\n",
            " 0.64928273 0.67400705 0.66480224 0.63723235 0.78698775 0.82552673\n",
            " 0.82255562 0.79046387 0.87954112 0.90480034 0.90319267 0.88484068\n",
            " 0.15689659 0.13104719 0.13332171 0.16390967 0.16116213 0.13891482\n",
            " 0.14428807 0.17588639 0.18119837 0.16433807 0.1723626  0.20247438\n",
            " 0.20809581 0.19686731 0.20703516 0.23456078 0.23594627 0.229243\n",
            " 0.24047415 0.2649044  0.25999369 0.25598786 0.26729234 0.28895938\n",
            " 0.66772783 0.70670464 0.69767658 0.65346688 0.64374602 0.66429943\n",
            " 0.65667185 0.63553963 0.53169055 0.54339348 0.53611332 0.52407803\n",
            " 0.64059874 0.65775776 0.65533996 0.64569892 0.79127643 0.82107809\n",
            " 0.82239655 0.80567326 0.89961626 0.91604048 0.91414898 0.90465026\n",
            " 0.14857158 0.12057364 0.12397194 0.15838371 0.15404759 0.12927486\n",
            " 0.13534958 0.17050727 0.17633992 0.1569203  0.16527393 0.19841835\n",
            " 0.20584008 0.19230082 0.20246509 0.23227948 0.23590567 0.22730562\n",
            " 0.23835386 0.2643985  0.2613278  0.25589539 0.2669593  0.28969521\n",
            " 0.6637771  0.69861764 0.69583935 0.66486453 0.63290233 0.6441356\n",
            " 0.64233116 0.63879866 0.52017216 0.52287916 0.52286606 0.53020842\n",
            " 0.63295255 0.63823166 0.64018159 0.64839161 0.79062067 0.80726443\n",
            " 0.81002747 0.80805068 0.9061486  0.9124535  0.90904826 0.90712671\n",
            " 0.15550669 0.1255075  0.12896981 0.16538339 0.16178386 0.13434372\n",
            " 0.13974857 0.17646597 0.18484088 0.16236887 0.16945811 0.20365604\n",
            " 0.21485149 0.1982091  0.20666836 0.23693837 0.24501637 0.23353902\n",
            " 0.24271933 0.2687667  0.27001281 0.26214227 0.27140865 0.29383487\n",
            " 0.65278034 0.67866432 0.67911555 0.66119297 0.62724957 0.62623936\n",
            " 0.6257202  0.6352952  0.52317308 0.51390728 0.51557495 0.53633103\n",
            " 0.63789749 0.62905939 0.62948305 0.64833888 0.79534446 0.7968711\n",
            " 0.79544102 0.8010958  0.90588099 0.90301189 0.89552496 0.89574843\n",
            " 0.17813458 0.14659846 0.14856162 0.18410982 0.1847281  0.1549496\n",
            " 0.15795784 0.19325913 0.20690407 0.18145947 0.18547838 0.21788632\n",
            " 0.23508832 0.21516312 0.22015178 0.24835898 0.26302183 0.24827944\n",
            " 0.25394276 0.27786146 0.2856263  0.27483084 0.28083949 0.30121165\n",
            " 0.64009158 0.65412314 0.65319438 0.64400344 0.63109943 0.61740977\n",
            " 0.61219905 0.62597874 0.54333895 0.52157094 0.51779626 0.5414852\n",
            " 0.6572375  0.6348211  0.62688908 0.64526248 0.80675767 0.79409474\n",
            " 0.78246066 0.78544477 0.90027484 0.89080899 0.87654291 0.87185716\n",
            " 0.2140221  0.18192756 0.18093921 0.21244019 0.22046194 0.18935806\n",
            " 0.18854012 0.2192458  0.24029966 0.21277724 0.21236623 0.24002935\n",
            " 0.26462862 0.24211863 0.2424256  0.26603627 0.28834407 0.27081936\n",
            " 0.27190899 0.29161201 0.30692002 0.29350717 0.29536812 0.31202408\n",
            " 0.72579643 0.76055613 0.74599463 0.69733627 0.73115659 0.7540215\n",
            " 0.74057015 0.70755486 0.62550548 0.63586001 0.61926036 0.59386366\n",
            " 0.72469041 0.74412793 0.73430867 0.71025701 0.85377366 0.88767903\n",
            " 0.88356481 0.85335345 0.95521521 0.98513645 0.98119898 0.95380676\n",
            " 0.2452609  0.22620662 0.22818607 0.25151752 0.2545135  0.24020415\n",
            " 0.24603032 0.27032206 0.27618816 0.26816984 0.27746311 0.30057194\n",
            " 0.30195621 0.30042331 0.31273826 0.33372722 0.32649612 0.33004274\n",
            " 0.34413547 0.36256046 0.34527585 0.35178586 0.36645704 0.3826333\n",
            " 0.73684972 0.7720485  0.76217097 0.72052887 0.72932609 0.74782421\n",
            " 0.73964842 0.71942896 0.61333708 0.62019217 0.61139518 0.60167158\n",
            " 0.71838373 0.7319259  0.72797236 0.71909276 0.85958208 0.8865934\n",
            " 0.88598556 0.868412   0.97588241 0.99767796 0.9922813  0.97142394\n",
            " 0.23042804 0.20868048 0.21153377 0.23891932 0.24098223 0.2236059\n",
            " 0.22981166 0.25778289 0.26529382 0.25416392 0.2633807  0.2895248\n",
            " 0.29434775 0.28992117 0.3017344  0.32489887 0.32192433 0.32296259\n",
            " 0.33629531 0.35612246 0.34298757 0.34744204 0.36124119 0.37819947\n",
            " 0.73603853 0.76806374 0.76305659 0.73176198 0.72333022 0.73480751\n",
            " 0.73115837 0.72455769 0.60572185 0.60688641 0.60487098 0.61079664\n",
            " 0.71419349 0.71946579 0.71951878 0.72468891 0.86116727 0.87846886\n",
            " 0.87901887 0.87267601 0.98156016 0.99422249 0.98628782 0.9707217\n",
            " 0.22771769 0.20350343 0.20634909 0.23615265 0.23896105 0.21838263\n",
            " 0.22372838 0.25357093 0.26437202 0.24957455 0.25719579 0.28457382\n",
            " 0.29467199 0.28641078 0.29602474 0.31969039 0.32330963 0.32063947\n",
            " 0.3314683  0.35122182 0.34505422 0.34616244 0.35742168 0.37390022\n",
            " 0.72803148 0.75354986 0.75117766 0.7297081  0.72085696 0.72366032\n",
            " 0.72093548 0.72357244 0.61106387 0.60496546 0.60520333 0.62095861\n",
            " 0.72053887 0.71637665 0.71554985 0.72798271 0.86599094 0.87238025\n",
            " 0.86936262 0.86774442 0.97730862 0.98169842 0.96925305 0.95455496\n",
            " 0.23894324 0.21285633 0.21438425 0.24397377 0.25019067 0.22680524\n",
            " 0.22979318 0.25879629 0.2749466  0.2565702  0.26098583 0.2870294\n",
            " 0.30410181 0.29177176 0.29757013 0.3194899  0.33147223 0.32460143\n",
            " 0.33138299 0.34918955 0.35197749 0.34910733 0.35643164 0.37092587\n",
            " 0.71535131 0.73215745 0.7288226  0.7136295  0.72301624 0.71693606\n",
            " 0.71030217 0.71469149 0.62898133 0.61522725 0.61166657 0.62814985\n",
            " 0.73644659 0.72322805 0.71571351 0.72588799 0.8730239  0.86908797\n",
            " 0.85743066 0.85190931 0.96360171 0.96184878 0.94302061 0.92379611\n",
            " 0.26292241 0.23600727 0.23499143 0.26143601 0.27352448 0.24836783\n",
            " 0.24779542 0.27307577 0.29600772 0.27493773 0.27501221 0.29709235\n",
            " 0.32183639 0.3061003  0.30708504 0.32506347 0.34582342 0.33518381\n",
            " 0.33706216 0.35117358 0.36335409 0.35675249 0.35943665 0.3706122 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y2_reg = SVR()\n",
        "Y2_reg.fit(x, Y2.reshape(-1))\n",
        "predY2 = Y2_reg.predict(x)\n",
        "print(predY2)"
      ],
      "metadata": {
        "id": "CANespVDlI0Z",
        "outputId": "b1fd15bc-0464-417b-ee64-fbe870eb5161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35243481 0.28914837 0.2945659  0.38102942 0.38910154 0.31049946\n",
            " 0.32205353 0.43901694 0.3467632  0.26032068 0.27397492 0.40360098\n",
            " 0.44726569 0.36518082 0.37612079 0.49848046 0.56333468 0.49370233\n",
            " 0.49925756 0.60065891 0.6044388  0.55454486 0.54528042 0.598642\n",
            " 0.10017559 0.06281587 0.06424896 0.10748873 0.09715127 0.06221354\n",
            " 0.06344645 0.10385873 0.10359813 0.07261841 0.07344483 0.10902973\n",
            " 0.1127574  0.08661358 0.08679392 0.11604187 0.12264682 0.10049145\n",
            " 0.10000018 0.12370886 0.13172323 0.1124705  0.11135098 0.1306457\n",
            " 0.46234345 0.40664224 0.40662813 0.4830754  0.4984393  0.41961248\n",
            " 0.42104791 0.53084234 0.43853391 0.34532983 0.34442468 0.46713391\n",
            " 0.55247755 0.46314362 0.45901239 0.57456237 0.68813135 0.61468659\n",
            " 0.60678822 0.70023364 0.70483893 0.65954081 0.64937331 0.70338965\n",
            " 0.10861127 0.06858355 0.067047   0.10980804 0.11071573 0.073916\n",
            " 0.07220716 0.11134862 0.12332484 0.09185896 0.09003404 0.12333246\n",
            " 0.1369857  0.11195024 0.11009725 0.13622585 0.14901653 0.12929489\n",
            " 0.12745854 0.14758496 0.15681644 0.14079282 0.13903021 0.15481748\n",
            " 0.48875113 0.4523676  0.44521705 0.49327054 0.52329374 0.46730897\n",
            " 0.45647494 0.52725416 0.45884992 0.38826678 0.37181571 0.45089593\n",
            " 0.57381702 0.50939464 0.49044973 0.56126705 0.71265966 0.66607432\n",
            " 0.64601953 0.69673886 0.71952845 0.69674702 0.68440281 0.71471859\n",
            " 0.1149188  0.07725129 0.07153852 0.10599359 0.11707957 0.08248202\n",
            " 0.07654526 0.10743007 0.13009532 0.10069118 0.0947909  0.12016455\n",
            " 0.14383856 0.12046843 0.11493759 0.13407892 0.1557273  0.13724936\n",
            " 0.13219179 0.14639034 0.16283037 0.14751504 0.14303011 0.15412988\n",
            " 0.49503165 0.48606301 0.47685109 0.49416618 0.52573858 0.50570657\n",
            " 0.49074012 0.51904561 0.4607605  0.42858753 0.40651946 0.43832899\n",
            " 0.5709805  0.54829254 0.52572161 0.54889099 0.70612782 0.70242479\n",
            " 0.68174323 0.68819683 0.70680333 0.71627367 0.7090469  0.7148187\n",
            " 0.12898228 0.09753524 0.0899261  0.11515398 0.12993255 0.10114984\n",
            " 0.09339792 0.115556   0.14163862 0.11740171 0.10983023 0.12732739\n",
            " 0.15399896 0.13463568 0.12761191 0.14030797 0.1648105  0.14919603\n",
            " 0.14279523 0.15193249 0.17103578 0.15742123 0.15170787 0.15910727\n",
            " 0.47661466 0.49924873 0.49632993 0.48938636 0.50063891 0.52460702\n",
            " 0.51837149 0.51289342 0.43893549 0.45552408 0.44303625 0.43728525\n",
            " 0.53931245 0.56922658 0.55932549 0.5455659  0.66467942 0.71368355\n",
            " 0.70836151 0.68190621 0.665176   0.71191953 0.71926872 0.70755843\n",
            " 0.14755627 0.12544979 0.11940184 0.13700426 0.14632619 0.12634398\n",
            " 0.12037781 0.13576941 0.15533834 0.13888499 0.13319704 0.14510515\n",
            " 0.16523806 0.15193726 0.14665283 0.15532736 0.17434891 0.16311406\n",
            " 0.15817876 0.16464444 0.17977804 0.16892129 0.16427334 0.1701153\n",
            " 0.43702475 0.48971975 0.50121814 0.48232316 0.45169736 0.51934407\n",
            " 0.53408771 0.51156812 0.39622918 0.46240908 0.473767   0.44895472\n",
            " 0.48290116 0.56588798 0.58339988 0.5521961  0.59381521 0.69487379\n",
            " 0.71879251 0.67878332 0.60015649 0.68205161 0.71157604 0.6942345\n",
            " 0.16867885 0.1573759  0.15616068 0.16925012 0.16494968 0.15522005\n",
            " 0.15440517 0.16630773 0.17059458 0.16322825 0.16272113 0.17238825\n",
            " 0.17759697 0.17146617 0.17091985 0.1787155  0.18479671 0.17886372\n",
            " 0.17802162 0.18463267 0.18966463 0.18236422 0.18097115 0.18758615\n",
            " 0.57234441 0.52378922 0.52619917 0.6006818  0.60057892 0.51794968\n",
            " 0.52054573 0.63767137 0.52063332 0.41700036 0.41712022 0.5534027\n",
            " 0.63572397 0.53138421 0.52636708 0.65723307 0.77637973 0.68677659\n",
            " 0.67679984 0.78487431 0.79094851 0.73864515 0.72920404 0.79264534\n",
            " 0.15140098 0.11040504 0.1103328  0.1564912  0.15838145 0.12024463\n",
            " 0.119651   0.16206057 0.1755543  0.14288881 0.14192865 0.17800065\n",
            " 0.19242285 0.16684366 0.1657349  0.19380343 0.20583007 0.18646132\n",
            " 0.1853931  0.20659229 0.21247011 0.1977568  0.1968824  0.21294657\n",
            " 0.59161313 0.56556145 0.56123568 0.60497308 0.61277582 0.55572585\n",
            " 0.5464187  0.62256857 0.52338284 0.44503497 0.43066365 0.52240327\n",
            " 0.64055509 0.56329431 0.54404353 0.62903182 0.7873066  0.72622409\n",
            " 0.70411302 0.76796857 0.79980239 0.76991674 0.75682796 0.79460263\n",
            " 0.14499993 0.10507056 0.10049019 0.13912459 0.15190651 0.11438379\n",
            " 0.10889416 0.14361578 0.16992859 0.13750528 0.13146645 0.15990947\n",
            " 0.18785321 0.16192325 0.15580121 0.1768766  0.20228137 0.18203661\n",
            " 0.17617174 0.19118266 0.20950034 0.19335732 0.18804981 0.19898419\n",
            " 0.5889907  0.5948039  0.58933617 0.59936357 0.60220687 0.58656378\n",
            " 0.57461211 0.60513137 0.5093312  0.47549645 0.45783942 0.49971283\n",
            " 0.6222527  0.59283598 0.57221404 0.60681879 0.76695249 0.75441947\n",
            " 0.73361239 0.75041284 0.77806328 0.78281607 0.7748144  0.78564327\n",
            " 0.14640529 0.11227118 0.10571789 0.13539425 0.15183588 0.1195009\n",
            " 0.11185333 0.13791483 0.16877899 0.14068678 0.13234168 0.15274352\n",
            " 0.18604669 0.1630257  0.15444685 0.16868221 0.20034784 0.18165186\n",
            " 0.17321305 0.18258858 0.20782727 0.19190236 0.18394683 0.19049761\n",
            " 0.56109863 0.60324159 0.60542538 0.58844654 0.56566506 0.60100896\n",
            " 0.60025784 0.59359746 0.47566506 0.49884161 0.49409423 0.49499779\n",
            " 0.57860502 0.61055716 0.60628273 0.60053685 0.7136329  0.76228982\n",
            " 0.76048863 0.7411949  0.72561342 0.77195887 0.7800571  0.77128175\n",
            " 0.15462139 0.13032999 0.1255745  0.14741702 0.15750464 0.13440172\n",
            " 0.12863478 0.14757384 0.17171642 0.15169311 0.14513461 0.15944786\n",
            " 0.18685845 0.16990965 0.16270894 0.17230529 0.20001692 0.18542314\n",
            " 0.17784262 0.18385296 0.20749361 0.19376525 0.18605661 0.19033155\n",
            " 0.51160041 0.5875187  0.60562015 0.57502468 0.50710364 0.59279675\n",
            " 0.61590954 0.58959739 0.42544227 0.50648322 0.52917372 0.50784812\n",
            " 0.51404235 0.60823829 0.63563113 0.60935505 0.63339743 0.74321395\n",
            " 0.77513922 0.73962726 0.64906779 0.73556279 0.76842384 0.75271237\n",
            " 0.1688256  0.1564975  0.15704152 0.17384332 0.16876083 0.15712975\n",
            " 0.15698128 0.17183953 0.17928402 0.16950367 0.16853099 0.17997984\n",
            " 0.19142195 0.18256424 0.18035324 0.1884554  0.20276578 0.19410087\n",
            " 0.19068619 0.19625831 0.21004158 0.20016663 0.19559486 0.20011193\n",
            " 0.63431928 0.60358293 0.61260779 0.6762685  0.6643642  0.59736878\n",
            " 0.60519319 0.71017009 0.5755447  0.48500501 0.49121967 0.61868993\n",
            " 0.68249269 0.5880586  0.5872515  0.70935138 0.81184235 0.72868835\n",
            " 0.72126576 0.82158278 0.84006128 0.79520401 0.78658978 0.83994162\n",
            " 0.2119061  0.17502322 0.17657582 0.22024988 0.22032008 0.18495512\n",
            " 0.18545518 0.22596546 0.23712718 0.20589961 0.20553691 0.24037338\n",
            " 0.25283024 0.22756606 0.22660085 0.25400928 0.26481165 0.24518503\n",
            " 0.24398065 0.26480352 0.26980276 0.25479726 0.2536575  0.2693162\n",
            " 0.65255463 0.64467322 0.6489679  0.68431181 0.67536617 0.63406759\n",
            " 0.63314915 0.7013941  0.57545359 0.51036147 0.50626678 0.5948635\n",
            " 0.68586593 0.61814172 0.6069123  0.68874468 0.82264141 0.76697949\n",
            " 0.75039938 0.81150961 0.8529681  0.82871176 0.81655158 0.84580472\n",
            " 0.19992221 0.16340592 0.16101142 0.19861098 0.20856194 0.17297806\n",
            " 0.16890024 0.20294413 0.22666959 0.1947286  0.18932063 0.217452\n",
            " 0.24406492 0.21740233 0.21112283 0.23206501 0.25770915 0.23611614\n",
            " 0.22953738 0.24433909 0.26392802 0.24642024 0.24006364 0.25044587\n",
            " 0.65104194 0.67436291 0.67834495 0.68192442 0.66620569 0.6653908\n",
            " 0.66363059 0.68987889 0.56217033 0.54073526 0.5358972  0.57928163\n",
            " 0.66960876 0.64846756 0.63816746 0.67430243 0.80540725 0.79658167\n",
            " 0.78300161 0.80127739 0.83466478 0.84280068 0.83541848 0.83943779\n",
            " 0.19518328 0.16373589 0.15959545 0.18928611 0.20286222 0.17174661\n",
            " 0.16554046 0.19167211 0.22057504 0.19226305 0.18435091 0.20483229\n",
            " 0.23810001 0.21368027 0.20448672 0.21855754 0.25230071 0.23162494\n",
            " 0.2218041  0.23059025 0.25934492 0.24146482 0.23164247 0.23699733\n",
            " 0.62651997 0.68428132 0.69492558 0.67221066 0.63396376 0.68191503\n",
            " 0.69080182 0.68166265 0.53335559 0.56677785 0.57457664 0.57916061\n",
            " 0.63180665 0.66966346 0.67533647 0.67337224 0.7585649  0.80841266\n",
            " 0.81321818 0.79741384 0.78495241 0.83210341 0.83963242 0.82512473\n",
            " 0.19786029 0.17554162 0.17292278 0.19514208 0.2035999  0.18114156\n",
            " 0.17642375 0.19548183 0.21934365 0.19867779 0.19203655 0.20613792\n",
            " 0.23550283 0.21689437 0.20844126 0.21722832 0.24913672 0.2324157\n",
            " 0.22272562 0.22724455 0.25654007 0.2407774  0.2304274  0.23245563\n",
            " 0.58100804 0.66952028 0.69329103 0.65630525 0.58082964 0.67573965\n",
            " 0.70546405 0.6762355  0.49016976 0.5781454  0.61015003 0.59174277\n",
            " 0.57499509 0.67180153 0.70594236 0.68275949 0.6863737  0.79428483\n",
            " 0.82975656 0.79704167 0.70983216 0.7944626  0.82462686 0.80323723\n",
            " 0.20744253 0.19640338 0.19831873 0.21516265 0.21075184 0.19931414\n",
            " 0.19943175 0.21381289 0.22345647 0.21283028 0.21099163 0.22137637\n",
            " 0.23717858 0.22670894 0.2224981  0.22872392 0.24936217 0.2387868\n",
            " 0.23256223 0.23545909 0.25668953 0.24508327 0.23723533 0.23831417]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1.3"
      ],
      "metadata": {
        "id": "7OPRTKmAaMaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.shape_base import split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from numpy.ma.core import reshape\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "yk-fx9dr6wRT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, xtest, ytrain, ytest = train_test_split(scaled_inputs, scaled_targets, test_size=0.2)"
      ],
      "metadata": {
        "id": "b_fJIvNd7YW5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM needs to be done in two parts as it cannot fit both Y's\n",
        "#Y1 training \n",
        "regressor_svm = SVR()\n",
        "regressor_svm.fit(x_train, ytrain[:,0])\n",
        "output_svm = regressor_svm.predict(xtest)\n",
        "cross_val_score = cross_val_score(regressor_svm, x_train, ytrain[:,0], scoring =\"neg_mean_squared_error\")*-1\n",
        "mse_SVM = (mean_squared_error(ytest[:,0], output_svm))"
      ],
      "metadata": {
        "id": "M0Vybk0FM4_I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Nf-z9todcnQH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y1 testing\n",
        "regressor_svm_ts = SVR()\n",
        "regressor_svm_ts.fit(xtest, ytest[:,0])\n",
        "output_svm = regressor_svm_ts.predict(xtest)\n",
        "cross_val_score = cross_val_score(regressor_svm_ts, xtest, ytest[:,0], scoring =\"neg_mean_squared_error\")*-1\n",
        "mse_SVM_ts = (mean_squared_error(ytest[:,0], output_svm))"
      ],
      "metadata": {
        "id": "YSQX0OR8aq7i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Sm8xwvIgUw8g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y2 training \n",
        "regressor_svm1 = SVR()\n",
        "regressor_svm1.fit(x_train, ytrain[:,1])\n",
        "output_svm1 = regressor_svm1.predict(xtest)\n",
        "cross_val_score = cross_val_score(regressor_svm1, x_train, ytrain[:,0], scoring =\"neg_mean_squared_error\")*-1\n",
        "mse_SVM1 = mean_squared_error(ytest[:,1], output_svm1)"
      ],
      "metadata": {
        "id": "NmHeqkE8Q7SH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "hISBA6tRdd3L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y2 Testing \n",
        "regressor_svm1_ts = SVR()\n",
        "regressor_svm1_ts.fit(xtest, ytest[:,1])\n",
        "output_svm1 = regressor_svm1_ts.predict(xtest)\n",
        "cross_val_score = cross_val_score(regressor_svm1_ts, xtest, ytest[:,0], scoring =\"neg_mean_squared_error\")*-1\n",
        "mse_SVM1_ts = mean_squared_error(ytest[:,1], output_svm1)"
      ],
      "metadata": {
        "id": "H3f_AMLSc_m5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions for models for random forest and neural network \n",
        "#for training\n",
        "y_pred_regressor_tr = regressor.predict(x_train)\n",
        "y_pred_regressor_NN_tr = regressor_NN.predict(x_train)\n",
        "\n",
        "#for testing\n",
        "y_pred_regressor = regressor.predict(xtest)\n",
        "y_pred_regressor_NN = regressor_NN.predict(xtest)"
      ],
      "metadata": {
        "id": "gd2cUjOgQa7C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating MSE\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "#for training\n",
        "mse_regressor_tr = mean_absolute_error(ytrain, y_pred_regressor_tr)\n",
        "mse_regressor_NN_tr = mean_absolute_error(ytrain, y_pred_regressor_NN_tr)\n",
        "\n",
        "#for testing\n",
        "mse_regressor = mean_absolute_error(ytest, y_pred_regressor)\n",
        "mse_regressor_NN = mean_absolute_error(ytest, y_pred_regressor_NN)\n"
      ],
      "metadata": {
        "id": "owIVbqa1R2HP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Testing MSE of Random Forest is {mse_regressor}\")\n",
        "print(f\"Training MSE of Random Forest is {mse_regressor_tr}\")\n",
        "print()\n",
        "\n",
        "print(f\"Training MSE of Neural Network is {mse_regressor_NN_tr}\")\n",
        "print(f\"Testing MSE of Neural Network is {mse_regressor_NN}\")\n",
        "print()\n",
        "\n",
        "print(f\"Training MSE of Support Vector Y1 is {mse_SVM}\")\n",
        "print(f\"Testing MSE of Support Vector Y1 is {mse_SVM_ts}\")\n",
        "print()\n",
        "\n",
        "print(f\"Training MSE of Support Vector Y2 is {mse_SVM1}\")\n",
        "print(f\"Testing MSE of Support Vector Y2 is {mse_SVM1_ts}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "7PdB2MUWinXA",
        "outputId": "3de5dc6a-c6d9-43d1-b272-18b481637adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing MSE of Random Forest is 0.0068657617578538116\n",
            "Training MSE of Random Forest is 0.006853008007414443\n",
            "\n",
            "Training MSE of Neural Network is 0.058387800140087646\n",
            "Testing MSE of Neural Network is 0.057467335128594935\n",
            "\n",
            "Training MSE of Support Vector Y1 is 0.004888237661566062\n",
            "Testing MSE of Support Vector Y1 is 0.005367386718194461\n",
            "\n",
            "Training MSE of Support Vector Y2 is 0.006487667849716329\n",
            "Testing MSE of Support Vector Y2 is 0.005852861671835386\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"BOXPLOT TESTING\")\n",
        "plt.boxplot([mse_regressor, mse_regressor_tr])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U2_6tqAi1jOO",
        "outputId": "f6430e15-e90c-4654-cba4-da007cff55d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pG87OsOa2A__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 \n"
      ],
      "metadata": {
        "id": "KqCNGlgozvk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list = []\n",
        "f = open(\"timetable.txt\", 'r')\n",
        "for line in f: list.append(line.split(\"|\"))\n",
        "f.close()\n",
        "print(list)"
      ],
      "metadata": {
        "id": "y8KxQgNYzu-I",
        "outputId": "9ea00aef-44bc-4459-f454-a101c72e836e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['MOD001', 'Zacharias Karstensen', '2', 'MOD002,MOD003,MOD004,MOD005,MOD006,MOD007,MOD008,MOD009,MOD010,MOD013 /\\n'], ['MOD002', 'Dominykas Cleary', '2', 'MOD001,MOD003,MOD004,MOD005,MOD006,MOD007,MOD008,MOD009,MOD010,MOD013 /\\n'], ['MOD003', 'Zacharias Karstensen', '2', 'MOD001,MOD002,MOD004,MOD005,MOD006,MOD007,MOD008,MOD009,MOD010,MOD011,MOD012,MOD013 /\\n'], ['MOD004', 'Laila Deniau', '1', 'MOD001,MOD002,MOD003,MOD005,MOD006,MOD007,MOD008,MOD009,MOD010,MOD011,MOD012,MOD013 /\\n'], ['MOD005', 'Brahma O Braonain', '2', 'MOD001,MOD002,MOD003,MOD004,MOD006,MOD007,MOD008,MOD009,MOD010,MOD011,MOD012 /\\n'], ['MOD006', 'Brahma O Braonain', '3', 'MOD001,MOD002,MOD003,MOD004,MOD005,MOD007,MOD008,MOD009,MOD010,MOD011,MOD012 /\\n'], ['MOD007', 'Ruh Kerekes', '1', 'MOD001,MOD002,MOD003,MOD004,MOD005,MOD006,MOD008,MOD009,MOD010,MOD011,MOD014,MOD015,MOD016,MOD017 /\\n'], ['MOD008', 'Brahma O Braonain', '2', 'MOD001,MOD002,MOD003,MOD004,MOD005,MOD006,MOD007,MOD009,MOD010,MOD011,MOD012,MOD014,MOD015 /\\n'], ['MOD009', 'Dominykas Cleary', '3', 'MOD001,MOD002,MOD003,MOD004,MOD005,MOD006,MOD007,MOD008,MOD010,MOD011,MOD012,MOD013 /\\n'], ['MOD010', 'Dominykas Cleary', '2', 'MOD001,MOD002,MOD003,MOD004,MOD005,M0D006,MOD007,MOD008,MOD009,MOD013 /\\n'], ['MOD011', 'Sumon Kyle', '2', 'MOD003,MOD004,MOD005,MOD006,MOD007,MOD008,MOD009,MOD012,MOD014,MOD015,MOD016,MOD017 /\\n'], ['MOD012', 'Minu Senft', '2', 'MOD003,MOD04,MOD005,MOD006,MOD007,MOD008,MOD009,MOD011,MOD014,MOD015 /\\n'], ['MOD013', 'Laila Deniau', '1', 'MOD001,MOD002,MOD003,MOD004,MOD009,MOD010 /\\n'], ['MOD014', 'Sumon Kyle', '2', 'MOD007,MOD008,M0D011,MOD012,MOD015,MOD016,MOD017 /\\n'], ['MOD015', 'Minu Senft', '2', 'MOD007,MOD008,MOD011,MOD012,MOD014,MOD016,MOD017 /\\n'], ['MOD016', 'Ruh Kerekes', '1', 'MOD007,MOD008,MOD011,MOD012,MOD014,MOD015,MOD017 /\\n'], ['MOD017', 'Ruh Kerekes', '1', 'MOD007,MOD008,MOD011,MOD012,MOD014,MOD015,MOD016 /']]\n"
          ]
        }
      ]
    }
  ]
}